{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/timomoeller/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "unfiltered data, num samples: 45885 with num features: 22\n",
      "filtered data with samples: 45885\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import seaborn as sns\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "%matplotlib inline\n",
    "#import xgboost\n",
    "\n",
    "train = pd.read_csv(\"../data/features/features.csv\",\n",
    "                    header=0,delimiter=\",\",quotechar='\"',error_bad_lines=False)\n",
    "\n",
    "print(\"unfiltered data, num samples: %i with num features: %i\" %(train.shape[0],train.shape[1]))\n",
    "\n",
    "train.fillna(' ',inplace=True)\n",
    "train.dropna(inplace=True)\n",
    "print(\"filtered data with samples: %i\" %(train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstracts = train[\"abstract\"].values\n",
    "idxthere = np.nonzero(abstracts != ' ')[0]\n",
    "useful = train[\"useful\"]\n",
    "abstracts = abstracts[idxthere]\n",
    "useful = useful[idxthere]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "documents = abstracts\n",
    "reRemoved = [re.sub(r'[^a-z ]', '', s.lower()) for s in documents]\n",
    "vect = CountVectorizer(max_df=0.6,min_df=10,stop_words=stopwords.words(\"english\"))\n",
    "bow = vect.fit_transform(reRemoved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# read in data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, useful, test_size=0.2, random_state=42)\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=6,n_estimators=200)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26522043386983907"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "np.mean(np.power(preds - y_test,2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
